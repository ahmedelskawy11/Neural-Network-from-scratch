{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time \n",
    "import random "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Layer Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, input_size, output_size , activation_function):\n",
    "        self.input = None\n",
    "        self.output = []\n",
    "        self.weights = []\n",
    "        self.activation_function = activation_function\n",
    "        ##nested loop to initailze the weigths with random values\n",
    "        for i in range(input_size):\n",
    "          col = []\n",
    "          for j in range(output_size):\n",
    "              col.append(random.random())\n",
    "          self.weights.append(col)\n",
    "        \n",
    "\n",
    "    def forward_propagation(self, given_input  ):\n",
    "        self.input = given_input\n",
    "        self.output = []\n",
    "        for col in range(len(self.weights[0])):\n",
    "            sum = 0 \n",
    "            for i in range(len(self.input) ):\n",
    "                sum += self.input[i] * self.weights[i][col]\n",
    "                \n",
    "            if self.activation_function == \"sigmoid\" :\n",
    "                self.output.append( 1/ (  1+(math.exp(-sum)) ))\n",
    "            \n",
    "            elif self.activation_function == \"tanh\" :\n",
    "                self.output.append( math.tanh(sum))\n",
    "\n",
    "        \n",
    "        return self.output\n",
    "        \n",
    "        \n",
    "    def back_propagation(self, previous_errors, learning_rate , targets):\n",
    "        \n",
    "        upcoming_error = []\n",
    "        for i in range( len(self.input)):\n",
    "            upcoming_error.append(0)\n",
    "\n",
    "        \n",
    "       #change the weights at the output layer\n",
    "        if len(previous_errors) == 0 :\n",
    "            for cur_neuron in range ( len(self.output) ) :\n",
    "                delta_j = ( targets[cur_neuron] - self.output[cur_neuron] ) * self.output[cur_neuron]  * (1-self.output[cur_neuron])\n",
    "\n",
    "                for upcoming_nueron in range( len( self.input) ) :\n",
    "                    upcoming_error[upcoming_nueron] += delta_j * self.weights[upcoming_nueron][cur_neuron] \n",
    "                    self.weights[upcoming_nueron][cur_neuron] += ( delta_j * self.input[upcoming_nueron] * learning_rate)\n",
    "\n",
    "      \n",
    "        #change the weights at the hidden layer\n",
    "        else :\n",
    "                \n",
    "            for cur_neuron in range ( len(self.output) ) :\n",
    "                delta_j = previous_errors[cur_neuron] * self.output[cur_neuron]  * (1-self.output[cur_neuron]) \n",
    "\n",
    "                for upcoming_nueron in range( len ( self.input) ) :\n",
    "                    \n",
    "                    upcoming_error[upcoming_nueron] += delta_j * self.weights[upcoming_nueron][cur_neuron] \n",
    "                    self.weights[upcoming_nueron][cur_neuron] += delta_j * learning_rate * self.input[upcoming_nueron]\n",
    "                    \n",
    "                    \n",
    "        return upcoming_error\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Network Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        self.loss = None\n",
    "\n",
    "    def add(self, layer ):\n",
    "        self.layers.append(layer )\n",
    "\n",
    "\n",
    "    def predict(self, input_data):\n",
    "        \n",
    "        predicted = []\n",
    "        for i in range( len(input_data) ):\n",
    "            output = input_data[i]\n",
    "            for layer in self.layers:\n",
    "                output = layer.forward_propagation(output )\n",
    "            predicted.append(output)\n",
    "\n",
    "        return predicted\n",
    "\n",
    "\n",
    "    def fit(self, train_data, train_labels, epochs, learning_rate):\n",
    "        \n",
    "        samples = len(train_data)\n",
    "\n",
    "        # training loop\n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            for sample in range(samples):\n",
    "        \n",
    "                cur_deltas = []\n",
    "                \n",
    "                output = train_data[sample]\n",
    "                \n",
    "                for layer in self.layers:\n",
    "                    output = layer.forward_propagation(output )\n",
    "\n",
    "\n",
    "                for layer in reversed(self.layers):\n",
    "                    cur_deltas = layer.back_propagation(cur_deltas, learning_rate , train_labels[sample])\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing With XOR Problem\n",
    "#### with tanh as an activation function for forwarding and sigmoid for backwarding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0], [0.7629303915095376], [0.7373012968003618], [0.3052037756363216]]\n"
     ]
    }
   ],
   "source": [
    "x_train = [ [0,0] , [0,1] , [1,0] , [1,1] ]\n",
    "y_train = [[0], [1], [1], [0]]\n",
    "\n",
    "# neural network init\n",
    "NN = Network()\n",
    "NN.add(Layer(2, 3 , \"tanh\"))\n",
    "NN.add(Layer(3, 1 , \"tanh\"))\n",
    "\n",
    "# train\n",
    "NN.fit(x_train, y_train, epochs=1000, learning_rate=0.1)\n",
    "\n",
    "# test\n",
    "predicted = NN.predict(x_train)\n",
    "\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Example Using Sigmod as an Activation Function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Points Belong To The First Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_points_1 = [ [1.0 , 2.] , [ 11.,8. ] , [ 0.5 , 0.2 ] , [ 2. , 0.8 ] , [12. , 6. ] , [11. , 7.] ]\n",
    "train_labels_1 = [ [0] , [0] , [0] , [0] , [0] , [0] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Points Belong To Second Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_points_2 = [ [1,7.5] , [10 , 2 ] , [ 3 , 8.5 ] , [ 2 , 9.2  ] , [11 , 1 ] , [9.6 , 3] ]\n",
    "train_labels_2 = [ [1] , [1] , [1] , [1] , [1] , [1] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network init\n",
    "\n",
    "NN_2 = Network()\n",
    "NN_2.add(Layer(2, 3 , \"sigmoid\"))\n",
    "NN_2.add(Layer(3, 1 , \"sigmoid\"))\n",
    "\n",
    "# train\n",
    "NN_2.fit(train_points_1, train_labels_1, epochs=100, learning_rate= 0.005)\n",
    "\n",
    "# test\n",
    "NN_2.fit(train_points_2, train_labels_2, epochs=100, learning_rate= 0.005)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.7604783459084058],\n",
       " [0.7986614154182426],\n",
       " [0.6939116168072398],\n",
       " [0.7550089349879301],\n",
       " [0.7985709034372972],\n",
       " [0.7986239214488585]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_2.predict(train_points_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.7961842824765544],\n",
       " [0.7965176292294784],\n",
       " [0.7982447147840177],\n",
       " [0.7981071306398067],\n",
       " [0.7952719373517435],\n",
       " [0.7974457582347836]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_2.predict(train_points_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
